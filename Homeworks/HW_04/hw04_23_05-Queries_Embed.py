# Müller Alexader
# \033[0;__;__m \033[m   or   \033[1;__;__m \033[m
# print('#' * 115)      # Для разделения блоков на листе с кодом:
""" ################################################################################################################
 23.05.25
 AI  &  Python 04:  Обработка запросов и таймаутов. Эмбеддинги и векторные представления.
 ################################################################################################################### """

# ------------------------ SHORTCUTS ------------------------
# Ctrl + W - выделить текущий блок. если нажимать это сочетание дальше, то будут выделяться родительские блоки.
# Ctrl+Y - Удаление всей строки. Кстати, команда копирования Ctrl+C без выделения также работает для всей строки.
# Ctrl+Akt+L / Alt+Enter - Привести код к принятым стандартам (для Python - PEP8).
# Ctrl+R — Изменить название класса/функции и т. п. по всему проекту.
# Ctrl+Shift + F - Найти по всем файлам.
# Shift + F6 - заменить имя элемента во всех частях во всех файлах.
# -----------------------------------------------------------

print('.' * 60)

""" ______  Task 1  ______________________________________________________________________________________________ """
# Обязательно к выполнению.
#   1) Добавить защиту от блокировки API (Rate Limits).
#   2) Обработать таймауты.
#   3) Реализовать retry-механизм с tenacity.


""" ///////////   Как получить API-key для Gemini от Google  /////////// """
#   1) Зайди на сайт Google AI Studio:
#       - Перейди по ссылке: https://makersuite.google.com/
#       - Войди в свой аккаунт под своей Google-учетной записью.
#   2) Согласись с условиями использования.
#   3) Открой вкладку "API Keys":
#       - В верхнем меню выбери пункт "API keys"
#         (или перейди сразу по ссылке: https://aistudio.google.com/app/apikey).
#   4) Сгенерируй ключ:
#       - Нажми кнопку "Create API Key", задай название (например, gemini-test-key) — и ключ будет создан.
#   5) Скопируй ключ и сохрани его в безопасном месте (например, в .env-файл или секреты IDE).


""" ///////////    Шаблон форматирования текста в консоли   /////////// """
# ++++++++++++++++++++++++++++++++++++++
import re                                   # Модуль для регулярных выражений.
# from example_text import example_text       # Текст для тестирования функции форматирования ответа в консоли.
# ++++++++++++++++++++++++++++++++++++++

# Функция, которая автоматически форматирует ответы от модели (Gemini) для вывода в
# окне Run в PyCharm с использованием цветов и стилей через ANSI-коды:
def format_gemini_response(response: str) -> str:
    """
    Принимает строку — ответ от модели (Gemini),
    и возвращает форматированную строку с ANSI-кодами для красивого вывода в консоль.
    """

    # ANSI-коды:
    RESET = '\033[0m';          BOLD_BACK = '\033[40;1m'
    BOLD = '\033[1m';           ITALIC = '\033[3m'
    UNDERLINE = '\033[4m'
    GREEN = '\033[32m'
    CYAN = '\033[36m'
    YELLOW = '\033[33m'
    MAGENTA = '\033[35m'
    RED = '\033[31m'
    BLUE = '\033[34m'
    GRAY = '\033[37m'

    formatted = response
    f = 30       # Number of fillers.
    # ..........................   Форматирование **жирного** текста в ЗАГОЛОВКАХ пунктов:
    pat_headers = r'^\*\*(.*?)\*\*$'
    formatted = re.sub(pat_headers, f"{BOLD_BACK}{MAGENTA}{' ▹▹▹  \\1 ':◃<{f}} {RESET}", formatted, flags=re.MULTILINE)
    # ..........................   Форматирование **жирного** текста:
    formatted = re.sub(r'\*\*(.*?)\*\*', f"{BOLD}\\1{RESET}", formatted)
    # ..........................   Форматирование *курсива*:
    formatted = re.sub(r'\*\b(.*?)\*', f"{ITALIC}{MAGENTA}\\1{RESET}", formatted)
    # ..........................   Преобразование заголовков Markdown вида "# Заголовок":
    pat_sections = r'^#{1,6} (.*)'
    formatted = re.sub(pat_sections, f"{BOLD_BACK}{MAGENTA}{' ▷▷▷  \\1 ':◁<{f}} {RESET}", formatted, flags=re.MULTILINE)
    # ..........................   Подчеркнутые строки, начинающиеся с подчёркивания (_) или «**_text_**»:
    formatted = re.sub(r'^_ (.*)', f"{UNDERLINE}\\1{RESET}", formatted, flags=re.MULTILINE)
    # ..........................   Маркированные списки 1-го уровня:
    formatted = re.sub(r'^[-*] (.*?)', f"{BOLD}{GREEN} ▶ \\1{RESET}", formatted, flags=re.MULTILINE)   # ※ ❇
    # Маркированные списки 2-го уровня:
    formatted = re.sub(r'^ {4}\* (.*?)', f"{BOLD}{MAGENTA}    ▷\\1{RESET}", formatted, flags=re.MULTILINE)   # ⩥ ▷ ▹
    # ..........................   Пронумерованные списки:
    formatted = re.sub(r'^(\d+)\. (.*?)', f"{BOLD}{GREEN}\\1. \\2{RESET}", formatted, flags=re.MULTILINE)
    # ..........................   Таблицы (просто подчёркивание заголовка таблиц):
    formatted = re.sub(r'^(.*\|.*)', f"{UNDERLINE}\\1{RESET}", formatted, flags=re.MULTILINE)

    return formatted


# # Для тестирования вида в форматировании:
# print(example_text)       # Текст без форматирования.
# formatted_output = format_gemini_response(example_text)
# print(formatted_output)




""" ___ 1) Добавить защиту от блокировки API (Rate Limits) ______________________________________________"""

# # +++++++++++++++++++++++++++++++++
# import time
# from google import genai
# from dotenv import load_dotenv
# import os
# # +++++++++++++++++++++++++++++++++
#
# # ___ 1 - Загрузка переменных окружения из файла .env:
# load_dotenv()
# api_key = os.getenv("GEMINI_API_KEY")
#
# # ___ 2 - Инициализирование клиента ChatGPT один раз вне функции для улучшения производительности:
# client = genai.Client(api_key=api_key)
#
# # ___ 3 - Функция отправки запроса к модели и получения ответа:
# def get_gemini_response(prompt):
#     """
#     Отправляет запрос к модели Gemini и возвращает текст ответа.#
#     :param prompt: Текст запроса.
#     :return: Текст ответа модели.
#     """
#
#     # Установка небольшой задержки перед отправкой запроса:
#     time.sleep(0.5)
#
#     # Использование глобального объекта клиента:
#     response = client.models.generate_content(
#         model="gemini-2.0-flash",
#         contents=[prompt],
#     )
#
#     return response.text
#
#
# # Пример использования:
# if __name__ == "__main__":
#     response = get_gemini_response(f"Объясни, пожалуйста, для студента первого курса инженерной специальности "
#                                    f"что такое Преобразование Фурье, как оно работает, какие бывают виды. "
#                                    f"Приведи примеры использования в жизни.")
#     formatted_output = format_gemini_response(response)
#     print(formatted_output)
#     # print(response)




""" ___ 2) Обработать таймауты ________________________________________________________________________ """

# В субботу 24.05.25 вылетала ошибка 503 - сервер перегружен.

# # +++++++++++++++++++++++++++++++++
# import time
# from google import genai
# from google.genai import types
# from dotenv import load_dotenv
# import os
# from requests import ReadTimeout
# # +++++++++++++++++++++++++++++++++
#
# # ___ 1 - Загружаем переменные окружения из файла .env:
# load_dotenv()
# api_key = os.getenv("GEMINI_API_KEY")
#
# # ___ 2 - Инициализируем клиент Gemini с таймаутом (в секундах):
# timeout_seconds = 10        # Установите желаемое значение таймаута.
# client = genai.Client(api_key=api_key, http_options=types.HttpOptions(timeout=timeout_seconds * 1000))
#
#
# # ___ 3 - Функция отправки запроса к модели и получения ответа:
# def get_gemini_response(prompt):
#     """
#     Отправляет запрос к модели Gemini и возвращает текст ответа.
#     Обрабатывает исключение TimeoutError.
#
#     :param prompt: Текст запроса.
#     :return: Текст ответа модели или None в случае таймаута.
#     """
#     # Небольшая задержка для предотвращения слишком частых запросов (настройте при необходимости)
#     time.sleep(0.3)
#
#     try:
#         response = client.models.generate_content(
#             model="gemini-2.0-flash",               # Используемая модель Gemini.
#             contents=[prompt]
#         )
#         return response.text                        # Возвращаем текст ответа.
#     except ReadTimeout:
#         # Выводим значение таймаута в секундах:
#         return f"Запрос к Gemini превысил таймаут ({timeout_seconds} секунд)."
#     except Exception as e:
#         # Общая обработка исключений для отлова неожиданных ошибок:
#         return f"Произошла ошибка: {str(e)}"
#
#
# if __name__ == "__main__":
#     response = get_gemini_response(f"Объясни, пожалуйста, для студента 1 курса физической специальности "
#                                    f"что такое волновая функция.")
#     if response:
#         formatted_output = format_gemini_response(response)
#         print(formatted_output)
#     else:
#         print("Не удалось получить ответ от Gemini.")



""" ___ 3) Реализовать retry-механизм с tenacity. ______________________________________________________ """

# # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# import time
# from tenacity import retry, stop_after_attempt, wait_exponential
# from google import genai
# from google.genai import types
# from dotenv import load_dotenv
# import os
# from requests import ReadTimeout
# # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
#
# load_dotenv()
# api_key = os.getenv("GEMINI_API_KEY")
#
# # Инициализируем клиент Gemini с таймаутом (в секундах)
# timeout_seconds = 10  # Установите желаемое значение таймаута
# client = genai.Client(api_key=api_key, http_options=types.HttpOptions(timeout=timeout_seconds * 1000))
#
# # Повторяем попытки подключения к серверу при сбое.
# # stop_after_attempt(3): останавливаемся после 3-й попытки.
# # wait_exponential(multiplier=1, min=2, max=10):
# #   - multiplier=1: начальное время ожидания 2 секунды.
# #   - min=2: минимальное время ожидания 2 секунды.
# #   - max=10: максимальное время ожидания 10 секунд.
# # Декторатор повтора запроса:
# @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
# def get_gemini_response(prompt):
#     """
#     Отправляет запрос к модели Gemini и возвращает текст ответа.
#     Обрабатывает исключение TimeoutError.
#
#     :param prompt: Текст запроса.
#     :return: Текст ответа модели или None в случае таймаута.
#     """
#
#     # Небольшая задержка для предотвращения слишком частых запросов (настройте при необходимости)
#     time.sleep(0.3)
#
#     try:
#         response = client.models.generate_content(
#             model="gemini-2.0-flash",               # Используемая модель Gemini.
#             contents=[prompt]
#         )
#         return response.text                        # Возвращаем текст ответа.
#     except ReadTimeout:
#         # Исправлено |=> выводим значение таймаута в секундах без преобразования:
#         return f"Запрос к Gemini превысил таймаут ({timeout_seconds} секунд)."
#     except Exception as e:
#         # Общая обработка исключений для отлова неожиданных ошибок:
#         return f"Произошла ошибка: {e}"
#
#
# if __name__ == "__main__":
#     response = get_gemini_response("Какие ошибки возникают при работе с API и как их решать?")
#     if response:
#         formatted_output = format_gemini_response(response)
#         print(formatted_output)
#     else:
#         print("Не удалось получить ответ от Gemini.")





""" ______  Task 2  ______________________________________________________________________________________________ """
# Дополнительно (по желанию).
#   1) Получить эмбеддинги двух разных текстов и сравнить их.
#   2) Реализовать простой поиск похожих текстов.


""" __________ 1) Получить эмбеддинги двух разных текстов и сравнить их. ____________________________ """

""" ___ 1.1) Получить эмбеддинги двух разных текстов: ____________ """
# Получение Эмбеддинга - преобразования текста в вектор. Для этого используется другая модель из genai:
# "text-embedding-004"

# # +++++++++++++++++++++++++++++++
# import os
# from dotenv import load_dotenv
# from google import genai
# import numpy as np                  #
# # +++++++++++++++++++++++++++++++
#
# # Загрузка переменных окружения из файла .env:
# load_dotenv()
#
# # Получение API-ключа из переменной окружения:
# api_key = os.getenv("GEMINI_API_KEY")
#
# # Инициализация клиента Gemini для работы с API:
# client = genai.Client(api_key=api_key)
#
#
# def get_embedding(text):
#     """
#     Получает embedding (векторное представление) для заданного текста.
#     :param text: Строка текста, для которого требуется получить embedding.
#     :return: Список чисел, представляющих векторное embedding.
#     """
#
#     # Отправка запроса к API для получения векторного представления текста:
#     response = client.models.embed_content(
#         model="text-embedding-004",
#         contents=text)
#
#     return np.array(response.embeddings[0].values)     # Возвращаем embedding как numpy array.
#
#
# # Получение embedding для заданных текстовых значений:
# query_1 = "Python - универсальный язык для ML."
# query_2 = "Обучение нейронных сетей."
# vector_1 = get_embedding(query_1)
# vector_2 = get_embedding(query_2)
#
# # Вывод полученных векторов с поясняющими сообщениями:
# # Описание ЦВЕТОВОГО оформления смотри по ссылке: https://pkg.go.dev/github.com/whitedevops/colors.
# # print(f'\033[7;33;40m {'*' * 60} \033[0m\n\n', f'\t\033[1;33m{query_1[:-1]}:\033[0m\n', vector_1)
# # print(f'\033[7;33;40m {'*' * 60} \033[0m\n\n', f'\t\033[1;33m{query_2[:-1]}:\033[m\n', vector_2)

""" ___ 1.2) Сравнение 2-х полученных Ембеддингов: ____________ """

# Метод	                    Когда использовать
# --------------------      -------------------------------------------------
# Косинусное сходство	    Когда важна направленность, а не длина векторов
# Евклид	                Когда важна «физическая близость»
# Манхэттен	                При работе с разреженными данными


""" 1. Косинусное сходство (Cosine Similarity) """
# — самый популярный способ, измеряет угол между двумя векторами.
# Близкий к 1 — векторы похожи, близкий к 0 — непохожи, близкий к -1 — противоположны.
# # ++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# from sklearn.metrics.pairwise import cosine_similarity
# # ++++++++++++++++++++++++++++++++++++++++++++++++++++++++
#
# similarity = cosine_similarity([vector_1], [vector_2])
# similar_y = 'Vectors are\033[33m enough\033[m similar.'
# similar_n = f'Vectors are\033[34m NOT\033[m enough similar.'
# similar_c = 'Vectors are controversy.'
# print(f"Cosine similarity: {similarity[0][0]:.3f}\n\t{similar_y if similarity>0.5 else similar_n}\n")


""" 2. Евклидово расстояние (Euclidean Distance) """
# — «физическое расстояние». Чем ближе к 0 — тем ближе векторы.
# # +++++++++++++++++++++++++++++++++++++++++++
# from scipy.spatial.distance import euclidean
# # +++++++++++++++++++++++++++++++++++++++++++
#
# distance = euclidean(vector_1, vector_2)
# print(f"Euclidean distance: {distance:.3f}\n")

""" 3. Манхэттенское расстояние (L1) """
# — сумма абсолютных разностей.
# # +++++++++++++++++++++++++++++++++++++++++++
# from scipy.spatial.distance import cityblock
# # +++++++++++++++++++++++++++++++++++++++++++
#
# manhattan = cityblock(vector_1, vector_2)
# print(f"Manhattan distance: {manhattan:.3f}")



""" __________ 2) Реализовать простой поиск похожих текстов. ____________________________ """

# +++++++++++++++++++++++++++++++++++
import os
import faiss
from dotenv import load_dotenv
from google import genai
import numpy as np
# +++++++++++++++++++++++++++++++++++

# Загрузка переменных окружения из файла .env:
load_dotenv()

# Получение API-ключа из переменной окружения:
api_key = os.getenv("GEMINI_API_KEY")

# Инициализация клиента Gemini для работы с API:
client = genai.Client(api_key=api_key)


def get_embedding(text):
    """
    Получает embedding (векторное представление) для заданного текста.
    :param text: Строка текста, для которого требуется получить embedding.
    :return: Список чисел, представляющих векторное embedding.
    """

    # Отправка запроса к API для получения векторного представления текста
    response = client.models.embed_content(
        model="text-embedding-004",
        contents=text)

    return np.array(response.embeddings[0].values)     # Возвращаем embedding как numpy array


# ---  Секция семантического поиска  ----------------------------------------------------------

# 1. Создание набора текстов для поиска
texts_to_index = [
    "6-ть правил психолога Михаила Лабковского могут помочь человеку снизить уровень тревожности",
    "Человек делает то, что хочется",
    "Человек не делает того, что не хочется",
    "Человек не отвечает, если не его не спрашивают",
    "Человек отвечает только на вопрос",
    "Человек сразу говорит другому человеку, если что-то ему не нравится",
    "Выясняя отношения, человек говорит только о себе",
    "Невротическое расстройство у людей связано с нарушением их личных границ",
    "Личные границы человека формируются изначально в семье",
    "Невротики составляют около 90 % населения планеты",
    "Именно невротики являются причиной социальных потрясений",
    "Человек, который не любит себя, не сможет полюбить другого",
    "Причиной невротического расстройства личности может стать любое травмирующее событие в жизни",
    "Важно, чтобы человек умел обозначать и оберегать свои личные границы",
    "Люди, которые проявляют чрезмерные эмоции, являются невротиками",
    "Человек в себе неуверенный постоянно ищет одобрения у других людей",
    "Человек, категорично высказывающийся о чем-либо, имеет невротические проявления",
    "Невротиками в большинстве своем становятся недолюбленные родителями дети",
    "Эпатажность - признак высокой степени невротизма и закомплексованности",
    "Уверенный в себе человек не интересуется мнением других о себе",
    "Человек, уверенный в себе, легко и просто говорит \"нет\" и способен адекватно оценить свои способности и возможности",
    "Тревожность - одно из проявлений невротического расстройства",
    "Хороший психолог способен помочь человеку уменьшить степень невротизма",
    "Современные СМИ искусственно культивируют и поддерживают невротическое состояние у людей",
    "Только человек с адекватными личными границами способен не впускать в себя то, что ему пытаются внушить невротики",
    "Профессия психолога домашних животных помогает лучше понять питомцев и обеспечить гармоничное и счастливое сосуществование.",
    "Знание особенностей психологии кошек важно для тех, кто содержит их как питомцев.",
    "Собаки, которых вырастили в заботе и любви, становятся чудесными питомцами.",
    "Нельзя очеловечивать домашних питомцев.",
    "Очеловечивание домашних питомцев приводит к постоянному нарушению их личных границ, а значит постоянному стрессу для них.",
    "Я люблю и кошек и собак.",
    "Мне нравится заботится о моей Масе и видеть ее довольной своей жизнью.",
    "Мася мурлычит каждый раз, когда я ее глажу.",
    "Фалькор любит спать в ногах.",
    "Мася и Фалькор - мои любимые котики.",
    "Мася - черная, уже старенькая кошка, а Фалькор - молодой, белый красавец-кот.",
    "Домашние кошки нуждаются в заботе и внимании.",
    "Как собаки, так и кошки - верные питомцы, особенно тем хозяевам, которых они полюбили."
]
# Количество фраз в списке texts_to_index:
print(f'Number of phrases in texts_to_index: {len(texts_to_index)}')

# 2. Получение embedding для каждого текста и сохранение их в списке:
embeddings_list = [get_embedding(text) for text in texts_to_index]
embeddings_array = np.array(embeddings_list)    # Преобразуем в numpy array для FAISS.

# 3. Создание FAISS индекса:
dimension = embeddings_array.shape[1]   # Размерность embedding.
index = faiss.IndexFlatL2(dimension)    # Используем IndexFlatL2 для L2 дистанции (евклидова).
index.add(embeddings_array)             # Добавляем embeddings в индекс.


# 4. Функция для выполнения семантического поиска:
def semantic_search(query, index, texts, k=2):
    """
    Выполняет семантический поиск по индексу FAISS.
    :param query: Поисковый запрос (строка).
    :param index: FAISS индекс.
    :param texts: Список текстов, которые были проиндексированы.
    :param k: Количество ближайших соседей для поиска (по умолчанию 2).
    :return: Список из k наиболее релевантных текстов.
    """
    query_embedding = get_embedding(query).reshape(1, -1)   # Получаем embedding для запроса и меняем размерность.
    D, I = index.search(query_embedding, k)                 # Ищем k ближайших соседей.
    results = [texts[i] for i in I[0]]                      # Получаем тексты по индексам.
    return results


# 5. Пример использования семантического поиска
search_query = "Что важно знать невротику?"
# search_query = "Забота о любимом питомце."
search_results = semantic_search(search_query, index, texts_to_index, k=5)

print(f"\n\033[0;36;40m{'---  Результаты семантического поиска  ':-<60}\033[0m")
print(f"\033[0;35mЗапрос:\033[0m '{search_query: <10}'")
print("\033[0;35mНайденные соответствия:\033[0m")
for i, result in enumerate(search_results, start=1):
    print(f"\033[0;35m{i}\033[0m - {result}")


"""  ___ Визуализация векторов в 2D (через PCA или t-SNE) ___________________________________________"""
# Чтобы визуализировать эмбеддинги в 2D и сравнить их, можно использовать метод понижения размерности,
# например, PCA или t-SNE. В текущей среде может быть не установлен пакет sentence-transformers,
# необходимый для получения эмбеддингов.
# Далее код, который можено запустить локально (например, в Jupyter Notebook или PyCharm):
# Установка необходимых библиотек:
# pip install sentence-transformers matplotlib scikit-learn

# ++++++++++++++++++++++++++++++++++++++++++++++++++++++
from sklearn.decomposition import PCA
from sklearn.metrics.pairwise import cosine_similarity      # косинусное сходство
import matplotlib.pyplot as plt
from sentence_transformers import SentenceTransformer
# ++++++++++++++++++++++++++++++++++++++++++++++++++++++

# Шаг 1: Модель для получения эмбеддингов
model = SentenceTransformer('all-MiniLM-L6-v2')

# Шаг 2: Примеры предложений
sentences = [
    "Кошка сидит на окне",
    "На подоконнике лежит кот",
    "Собака бегает по парку",
    "Стул стоит у стены"
]

# Шаг 3: Получаем эмбеддинги:
# embeddings = model.encode(sentences)
embeddings = model.encode(texts_to_index)       # Список фраз из задания по семантическому поиску: Task 2.2.

# Шаг 4: Считаем косинусное сходство:
similarities = cosine_similarity(embeddings)
print("Косинусное сходство:\n", similarities)

# Шаг 5: Уменьшаем размерность для визуализации:
pca = PCA(n_components=2)
reduced = pca.fit_transform(embeddings)

# Шаг 6: Визуализация:
plt.figure(figsize=(8, 6))
# colors = ['green', 'green', 'red', 'blue']

# Генерация градиента из 38 цветов для всех фраз в списке texts_to_index:
    # Выбираем colormap: 'jet' — от синего через жёлтый к красному:
cmap = plt.get_cmap('jet')
    # Генерация 38 равномерных значений от 0 до 1
colors = [cmap(i / 37) for i in range(38)]
#     # Преобразуем цвета в формат HEX (удобно использовать в HTML или визуализациях)
# hex_colors = [plt.colors.to_hex(c) for c in colors]
#     # Все 38 цветов:
# for i, color in enumerate(hex_colors, 1):
#     print(f"{i:2d}: {color}")

# Ассоциация списка цветов со списком фраз texts_to_index:
for i, (x, y) in enumerate(reduced):
    plt.scatter(x, y, color=colors[i])
    plt.text(x + 0.01, y + 0.01, texts_to_index[i][:10], fontsize=8)

print(f"\n\033[0;36;40m{'---  Визуализация векторов в 2D (через PCA или t-SNE)  ':-<60}\033[0m")

plt.title("Визуализация эмбеддингов (PCA)")
plt.grid(True)
plt.tight_layout()
plt.show()

